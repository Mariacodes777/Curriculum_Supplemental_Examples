{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5006b6d4",
   "metadata": {},
   "source": [
    "### This Notebook is Designed to Walkthrough Lesson 3 in Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6aadcf",
   "metadata": {},
   "source": [
    "### Decision Trees in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b67caa",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4575fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37d8157",
   "metadata": {},
   "source": [
    "### Load Data: \n",
    "This Data is built into the seaborn package\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85afa707",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = sns.load_dataset('iris')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539c5103",
   "metadata": {},
   "source": [
    "Use the .head() to view the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "740e39ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa\n",
       "3           4.6          3.1           1.5          0.2  setosa\n",
       "4           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c07c45c",
   "metadata": {},
   "source": [
    "### Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09bc892",
   "metadata": {},
   "source": [
    "Specify the x and y variables using subsetting. y is the column you are predicting, and x is everything being using to predict it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b099a0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = iris.drop('species', axis=1)\n",
    "y = iris['species']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0882eb2",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ac078d",
   "metadata": {},
   "source": [
    "Split the data into training and testing sets. The train variables are creating the initial model, and the test variables are what will be used to determine the fit of the model. Note that just for following along, set the random_state to 76, which is not necessary, but it will give the same result as the example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "425028e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.3, random_state=76)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42cc3cb9",
   "metadata": {},
   "source": [
    "### Create Initial Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1bb2efa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(random_state=76)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decisionTree = DecisionTreeClassifier(random_state=76)\n",
    "decisionTree.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb2bdf3",
   "metadata": {},
   "source": [
    "### Assess the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e1f50e",
   "metadata": {},
   "source": [
    "Create a set of predictions and interpret the results. Start by using the predict() function, and then utilize the same confusion matrix and classification report coding as in previous lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91d31e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "treePredictions = decisionTree.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b29787",
   "metadata": {},
   "source": [
    "### Print Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38c03452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[19  0  0]\n",
      " [ 0 10  3]\n",
      " [ 0  2 11]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, treePredictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5efd640",
   "metadata": {},
   "source": [
    "The variables on the top represent the actual values, and the variables on the side represent the predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "203d318f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#                        setosa (actual)    versicolor (actual)  virginica (actual)\n",
    "#setosa (predicted)            19                   0                     0\n",
    "#versicolor (predicted)        0                    10                    3\n",
    "#virginica (predicted)         0                    2                     11"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb762425",
   "metadata": {},
   "source": [
    "In the upper left corner is the number 19. Because this is marked setosa both in the column and the row, that means that these are the predictions that were right! So, 19 irises were classified as the species setosa and actually were a setosa. Moving to the next column, same row, is the number 0. This means that there were no irises in the setosa species that were accidentally classified as versicolor. Similarly, in the third column, there were no irises accidentally classified in our model as virginica.\n",
    "\n",
    "If you move on to the second row, for versicolor, you can see that no versicolor irises were accidentally misclassified as setosa. In the next column, you can note that 10 irises were versicolor, and actually were classified as versicolor. Then in the last column, you see that there were three versicolor irises that were misclassified as virginica species instead.\n",
    "\n",
    "For the third row, there were no virginica irises misclassified as setosa, there were two misclassified as versicolor, and there were eleven properly classified as virginica.\n",
    "\n",
    "So this decision tree model is really good at predicting the species of setosa, but misclassified a few of the versicolor species as virginica and vice versa.\n",
    "\n",
    "(page 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0691c3",
   "metadata": {},
   "source": [
    "<img src=\"https://miro.medium.com/max/700/1*uo6VfVH87jRjMZWVdwq3Vw.png\" jsaction=\"load:XAeZkd;\" jsname=\"HiaYvf\" class=\"n3VNCb\" alt=\"Nivitus | Medium\" data-noaft=\"1\" style=\"width: 450px; height: 201.214px; margin: 0px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d3ca4b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#source of above image: https://miro.medium.com/max/700/1*uo6VfVH87jRjMZWVdwq3Vw.png"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7cbf70",
   "metadata": {},
   "source": [
    "### How Well Does your Model Fit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0bbee64a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        19\n",
      "  versicolor       0.83      0.77      0.80        13\n",
      "   virginica       0.79      0.85      0.81        13\n",
      "\n",
      "    accuracy                           0.89        45\n",
      "   macro avg       0.87      0.87      0.87        45\n",
      "weighted avg       0.89      0.89      0.89        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, treePredictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbc4266",
   "metadata": {},
   "source": [
    "First look at precision. Precision is the total number of true positives are divided by the total of positives, whether true or false."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4936404d",
   "metadata": {},
   "source": [
    "Next, look at recall. So instead of putting the true positives over all positives, you put it over the sum of the true positives and the false negatives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644d1365",
   "metadata": {},
   "source": [
    "Then, look at the F1-score. F1 is equal to 2x precision x recall / precision + recall. Please review the formulas on page 4. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2076a338",
   "metadata": {},
   "source": [
    "So setosa was predicted with 100% precision, while versicolor was predicted with 83% accuracy and virginica was predicted with 79% accuracy! We can predict the species of the flower with 89% accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a952e4",
   "metadata": {},
   "source": [
    "### Random Forest in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027965e4",
   "metadata": {},
   "source": [
    "We did one tree now we will do a forest!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd7ac50",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc827455",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf419723",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d8b3fffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = sns.load_dataset('iris')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ade2fa",
   "metadata": {},
   "source": [
    "### Data Wrangling\n",
    "Subsetting the Data again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c796cb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = iris.drop('species', axis=1)\n",
    "y = iris['species']\n",
    "#We are dropping the species column to use it as the predictor variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b34850",
   "metadata": {},
   "source": [
    "### Test Train Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2489b91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.3, random_state=76)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc59682",
   "metadata": {},
   "source": [
    "### Initial Random Forest Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ddd6e7a",
   "metadata": {},
   "source": [
    "We will use the RandomForestClassifer(), with the arguments n_estimators= to specify how many decision trees we want the random forest to stem from, and random_state= just to follow along with this example:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b41b9bf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=500, random_state=76)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest = RandomForestClassifier(n_estimators=500, random_state=76)\n",
    "forest.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3201a994",
   "metadata": {},
   "source": [
    "The n_estimators=, which we have set to 500 means we will be testing our data with 500 decision trees. In general, the higher the n_estimators=, the more accurate the model will be."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5355f83e",
   "metadata": {},
   "source": [
    "### Evaluate Model Fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90faa83",
   "metadata": {},
   "source": [
    "Using both the confusion matrix and classification report again here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dc94b449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[19  0  0]\n",
      " [ 0 11  2]\n",
      " [ 0  0 13]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        19\n",
      "  versicolor       1.00      0.85      0.92        13\n",
      "   virginica       0.87      1.00      0.93        13\n",
      "\n",
      "    accuracy                           0.96        45\n",
      "   macro avg       0.96      0.95      0.95        45\n",
      "weighted avg       0.96      0.96      0.96        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "forestPredictions = forest.predict(x_test)\n",
    "print(confusion_matrix(y_test, forestPredictions))\n",
    "print(classification_report(y_test, forestPredictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c260809",
   "metadata": {},
   "source": [
    "The model is 96% accurate. There is 100% accuracy for both setosa and versicolor irises, but only 87% accuracy for virginica."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90a46f5",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af5a3a9",
   "metadata": {},
   "source": [
    "In machine learning, parameters are the components of the model. Parameters that are adjustable are called hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a24cd8",
   "metadata": {},
   "source": [
    "### Load Additional Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8dc9d65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ad7722",
   "metadata": {},
   "source": [
    "There are four hyperparameters for decision trees and random forests that are important:\n",
    "\n",
    "-Maximum depth: how far down the \"roots\" of your tree go. How many nodes do you allow?\n",
    "\n",
    "-Number of estimators: determining how many trees to be using.\n",
    "\n",
    "-Maximum number of features: A feature is the decision points, or branches, on the tree.\n",
    "\n",
    "-Minimum number of samples for a leaf: The minimum number of samples is how many data points are being sorted at each feature. \n",
    "(page 6/7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763681a6",
   "metadata": {},
   "source": [
    "### Number of Estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d0eebe",
   "metadata": {},
   "source": [
    "1) Determine how many trees you will be using. \n",
    "\n",
    "2) Create an array that contains the most likely number of estimators, which is what is shown in the first line of code below.\n",
    "\n",
    "3) Then create an empty list named results that will end up filled using a for loop!\n",
    "\n",
    "4) Then the for loop, this iterates over your n_estimators_array and creates a random forest for each, prints out the accuracy for each, and finally adds it to your results list. The very last line in the for loop prints out each result as it becomes available. (page 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fa1933a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : 0.9111111111111111\n",
      "4 : 0.9555555555555556\n",
      "5 : 0.9333333333333333\n",
      "8 : 0.9555555555555556\n",
      "10 : 0.9777777777777777\n",
      "20 : 0.9555555555555556\n",
      "50 : 0.9555555555555556\n",
      "75 : 0.9555555555555556\n",
      "100 : 0.9555555555555556\n",
      "250 : 0.9555555555555556\n",
      "500 : 0.9555555555555556\n"
     ]
    }
   ],
   "source": [
    "n_estimators_array = [1, 4, 5, 8, 10, 20, 50, 75, 100, 250, 500]\n",
    "results = []\n",
    "for n in n_estimators_array:\n",
    "    forest = RandomForestClassifier(n_estimators=n, random_state=76)\n",
    "    forest.fit(x_train, y_train)\n",
    "    result = accuracy_score(y_test, forest.predict(x_test))\n",
    "    results.append(result) \n",
    "    print(n, ':', result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f3e1ab",
   "metadata": {},
   "source": [
    "So it looks like the best accuracy arises when you use only 10 trees instead of the standard 500! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1fad3ae",
   "metadata": {},
   "source": [
    "To view this result visually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2decabbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x28c9f7d90>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(n_estimators_array, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13135a41",
   "metadata": {},
   "source": [
    "We see from this graph that things have completely stagnated before 100 trees, so it certainly is a waste of processing power to request 500."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2550a0de",
   "metadata": {},
   "source": [
    "### Tuning the Remaining Three"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce02e89",
   "metadata": {},
   "source": [
    "Below you are creating lists with all the hyperparameter values you want to trial. There is one for each of the remaining three features, named: max_features, max_depth, and min_samples_leaf. Then, you'll create a dictionary with the hyperparameter names as the keys and the list variables as the values. This is called a grid and is aptly named random_grid.(page 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "102776e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_features': ['auto', None, 'log2'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, None], 'min_samples_leaf': [1, 2, 4]}\n"
     ]
    }
   ],
   "source": [
    "# Number of features to consider at every split\n",
    "max_features = ['auto', None, 'log2']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [10, 20, 30, 40, 50, 60, 70, 80, 90, None]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "random_grid = {'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_leaf': min_samples_leaf}\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81e984f",
   "metadata": {},
   "source": [
    "Preparing to initialize one random forest for every one of those hyperparameters in the random_grid. Since you know that you only want ten trees, the first line sets up a random forest model with that.\n",
    "\n",
    "The next line of code gives you a random search of the random_grid you created using the function RandomizedSearchCV(). The arguments for that function include the estimator=, which is what you've named your latest iteration of the random forest with only ten estimators, the param_distributions= argument, which is where you plug in the random_grid dictionary, n_iter=, which is the number of iterations, or times to complete the random forest, and lastly, the cv= argument, which allows you to choose how many folds you'd like in your cross validation. The random_state= argument is not required to run code, but including it means that your results should be the same as those in the lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "65627650",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=10)\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 90, cv = 3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a792ff1",
   "metadata": {},
   "source": [
    "### Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7a984066",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=RandomForestClassifier(n_estimators=10),\n",
       "                   n_iter=90,\n",
       "                   param_distributions={'max_depth': [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90, None],\n",
       "                                        'max_features': ['auto', None, 'log2'],\n",
       "                                        'min_samples_leaf': [1, 2, 4]},\n",
       "                   random_state=42)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1dfba94",
   "metadata": {},
   "source": [
    "### See which Hyperparameter Produced the Best Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7b08bbf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'min_samples_leaf': 2, 'max_features': None, 'max_depth': 20}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d21209",
   "metadata": {},
   "source": [
    "This is showing the best parameters were to have 2 leafs per sample, no max features, and a maxium depth of 20."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9823a185",
   "metadata": {},
   "source": [
    "Applying those parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bdb18e08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=20, max_features=None, min_samples_leaf=2,\n",
       "                       n_estimators=10)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest = RandomForestClassifier(n_estimators=10, min_samples_leaf=2, max_features=None, max_depth=20)\n",
    "forest.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "111ad88d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[19  0  0]\n",
      " [ 0 12  1]\n",
      " [ 0  0 13]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        19\n",
      "  versicolor       1.00      0.92      0.96        13\n",
      "   virginica       0.93      1.00      0.96        13\n",
      "\n",
      "    accuracy                           0.98        45\n",
      "   macro avg       0.98      0.97      0.97        45\n",
      "weighted avg       0.98      0.98      0.98        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "forestPredictions = forest.predict(x_test)\n",
    "print(confusion_matrix(y_test, forestPredictions))\n",
    "print(classification_report(y_test, forestPredictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f299e05b",
   "metadata": {},
   "source": [
    "Overall accuracy is 98%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17308934",
   "metadata": {},
   "source": [
    "### Feature Importance\n",
    "(One of my favorite parts of ML!!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4961ce0b",
   "metadata": {},
   "source": [
    "Evaluating the feature importance just means that you can figure out which variable makes more difference to the prediction of the y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3764ca4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sepal_length    0.007823\n",
       "sepal_width     0.003542\n",
       "petal_length    0.553005\n",
       "petal_width     0.435630\n",
       "dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances = pd.Series(forest.feature_importances_, index=x.columns)\n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4042ffb",
   "metadata": {},
   "source": [
    "The sort_values() function will sort them. The inplace=True argument, like always, makes this change permanent, and ascending=False means that this goes from largest to smallest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a532f5de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "petal_length    0.553005\n",
      "petal_width     0.435630\n",
      "sepal_length    0.007823\n",
      "sepal_width     0.003542\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "feature_importances.sort_values(inplace=True, ascending=False)\n",
    "print(feature_importances)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8abb93",
   "metadata": {},
   "source": [
    "View the results in a little graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5c641f2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_importances.plot(kind='barh', figsize=(7,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc4f15c",
   "metadata": {},
   "source": [
    "This makes it really easy to see which variable(s) was the top predictors of y."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4502660c",
   "metadata": {},
   "source": [
    "Hope you enjoyed this walkthrough of Lesson 3 from ML! Explanation verbage from pages 4-8:) <3 Mia"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
